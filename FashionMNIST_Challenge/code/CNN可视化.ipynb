{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/artemis/venv/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From /home/artemis/venv/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "step 0, training accuracy :0.09375\n",
      "step 100, training accuracy :0.804688\n",
      "step 200, training accuracy :0.796875\n",
      "step 300, training accuracy :0.8125\n",
      "step 400, training accuracy :0.867188\n",
      "test accuracy :0.8271\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "mnist = input_data.read_data_sets(\"data/fashion\", one_hot=True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 网络参数\n",
    "n_input = 784 \n",
    "n_classes = 10 \n",
    "dropout = 0.75 \n",
    "\n",
    "\n",
    "with tf.name_scope('input_data') as scope:\n",
    "    x = tf.placeholder(tf.float32, [None, n_input] ,name='input')\n",
    "    y = tf.placeholder(tf.float32, [None, n_classes], name='label')\n",
    "    keep_prob = tf.placeholder(tf.float32, shape=(), name='drop_out') \n",
    "\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')\n",
    "\n",
    "\n",
    "# 创建模型\n",
    "def conv_net(x,dropout):\n",
    "    with tf.name_scope('model') as scope:\n",
    "        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "        # 卷积层\n",
    "        # Max Pooling (down-sampling)\n",
    "        with tf.name_scope('layer1') as scope:\n",
    "            W_conv1 = tf.Variable(tf.random_normal(shape=[5,5,1,32]), name='weight')\n",
    "            b_conv1 = tf.Variable(tf.random_normal(shape=[1,32]), name='bias')\n",
    "            convOne = tf.nn.conv2d(x, W_conv1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "            reluOne = tf.nn.relu(convOne + b_conv1)\n",
    "            conv1 = tf.nn.max_pool(reluOne, ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "\n",
    "        # 卷积层\n",
    "        with tf.name_scope('layer2') as scope:\n",
    "            W_conv2 = tf.Variable(tf.random_normal(shape=[5,5,32,64]), name='weight')\n",
    "            b_conv2 = tf.Variable(tf.random_normal( shape=[1,64]), name='bias')\n",
    "            convTwo = tf.nn.conv2d(conv1, W_conv2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "            reluTwo = tf.nn.relu(convTwo + b_conv2)\n",
    "            conv2 = tf.nn.max_pool(reluTwo, ksize=[1,2,2,1], strides=[1,2,2,1],padding=\"SAME\")\n",
    "\n",
    "        # 全连接层\n",
    "        # Reshape conv2 适合全连接层的输入输出\n",
    "        with tf.name_scope('full_connect') as scope:\n",
    "            W_full = tf.Variable(tf.random_normal(shape=[7 * 7 * 64, 1024]), name='weight')\n",
    "            b_full = tf.Variable(tf.random_normal(shape=[1, 1024]), 'bias')\n",
    "            input_flat=tf.reshape(conv2, shape=[-1, 7 * 7 * 64])\n",
    "            fc1 = tf.nn.relu(tf.matmul(input_flat, W_full) + b_full)\n",
    "\n",
    "        with tf.name_scope('soft_max') as scope:\n",
    "            drop_out = tf.nn.dropout(fc1,keep_prob)\n",
    "\n",
    "        # 类预测输出\n",
    "            W_softmax = tf.Variable(tf.truncated_normal(shape=[1024, 10]), name='weight')\n",
    "            b_softmax = tf.Variable(tf.truncated_normal(shape=[1,10]), name='bias')\n",
    "            y_predict = tf.matmul(drop_out, W_softmax) + b_softmax\n",
    "\n",
    "        return y_predict\n",
    "    # 构建模型\n",
    "\n",
    "pred = conv_net(x, keep_prob)\n",
    "\n",
    "with tf.name_scope('result') as scope:\n",
    "    # 定义损失和优化器\n",
    "    cross_entropy_cnn = -y * tf.nn.log_softmax(pred)\n",
    "    cost = tf.reduce_sum(cross_entropy_cnn, name='cost') ### 目标函数有问题\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # 评估模型\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "cost_summary = tf.summary.scalar(cost.op.name, cost)\n",
    "accuracy_summary = tf.summary.scalar(accuracy.op.name, accuracy)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "summary_op = tf.summary.merge([cost_summary, accuracy_summary])\n",
    "summary_writer = tf.summary.FileWriter('/home/artemis/graphs',sess.graph)\n",
    "\n",
    "for i in range(500):\n",
    "    batch = mnist.train.next_batch(128)\n",
    "\n",
    "    if i% 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y:batch[1], keep_prob:1.0},session=sess)\n",
    "        print (\"step \"+ str(i) +\", training accuracy :\"+ str(train_accuracy))\n",
    "        cross_entropy_val = cross_entropy_cnn.eval(feed_dict={x:batch[0], y:batch[1], keep_prob:1.0},session=sess)\n",
    "\n",
    "        summary_str = sess.run(summary_op, feed_dict={x:batch[0], y:batch[1], keep_prob:(1.0)})\n",
    "        summary_writer.add_summary(summary_str, i)\n",
    "\n",
    "    sess.run(optimizer, feed_dict={x:batch[0], y:batch[1], keep_prob:0.75})\n",
    "print(\"test accuracy :\" + str(accuracy.eval(feed_dict={x:mnist.test.images, y:mnist.test.labels, keep_prob:1.0},session=sess)))\n",
    "sess.close()\n",
    "summary_writer.close()  ##程序运行结束后关闭文件并刷新到硬盘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
